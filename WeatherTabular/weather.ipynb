{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.curdir, 'AllData')\n",
    "data_path = os.path.join(data_folder, 'weather.tsv')\n",
    "df = pd.read_csv(data_path, sep='\\t')  \n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['wind_direction'], bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('Wind Speed')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Wind Direction Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we notice that wind direction have values more than 360 degress which is not possible\n",
    "# I think it is a mistake in the data so we will replace it with the same value subtracted by 360 because most of the wind direction comes from the north in Jordan as we saw in the plot above\n",
    "df.loc[df['wind_direction'] > 360, 'wind_direction'] = df['wind_direction'] - 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['temperature'], bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Temperature Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['wind_speed'], bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('Wind Speed')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Wind Speed Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['wind_direction'], bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('Wind Speed')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Wind Direction Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['dew_point'], bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('Dew Point')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Dew Point Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['visibility'], bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('Visibility')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Visibility Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['clouds.total_cover'], bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('Coulds Total Cover')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Coulds Total Cover Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='dew_point', data=df, color='green')\n",
    "plt.xlabel('Dew Point')\n",
    "plt.title('Dew Point Box Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='temperature', data=df, color='green')\n",
    "plt.xlabel('Temperature')\n",
    "plt.title('Temperature Box Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='wind_speed', data=df, color='green')\n",
    "plt.xlabel('Wind Speed')\n",
    "plt.title('Wind Speed Box Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='wind_direction', data=df, color='green')\n",
    "plt.xlabel('Wind Direction')\n",
    "plt.title('Wind Direction Box Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='visibility', data=df, color='green')\n",
    "plt.xlabel('Visibility')\n",
    "plt.title('Visibility Box Plot')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='clouds.total_cover', data=df, color='green')\n",
    "plt.xlabel('Clouds Total Cover')\n",
    "plt.title('Clouds Total Cover Box Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['time'], df['temperature'], label='Temperature', color='red')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Temperature Time Series')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['time'], df['temperature'], label='Temperature', color='red')\n",
    "plt.plot(df['time'], df['dew_point'], label='Dew Point', color='blue')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Temperature and Dew Point Time Series')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation matrix and plot it\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values,\n",
    "            cmap='Blues')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the highest correlation\n",
    "corr.abs().unstack().sort_values(ascending=False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = range(1, 25)  # Change this range as needed\n",
    "autocorrelation_values = [df['temperature'].autocorr(lag=lag) for lag in lags]\n",
    "\n",
    "# Display the autocorrelation values for different lags\n",
    "for lag, acf in zip(lags, autocorrelation_values):\n",
    "    print(f'Lag {lag}: Autocorrelation = {acf}')\n",
    "\n",
    "# Plot the autocorrelation values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(lags, autocorrelation_values)\n",
    "plt.xlabel('Lag (Hours)')\n",
    "plt.ylabel('Auto-Correlation')\n",
    "plt.title('Auto-Correlation of Temperature at Different Lags')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the data is time-series, we need to split it based on time\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(df))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = df[:split_index]\n",
    "test_data = df[split_index:]\n",
    "\n",
    "# Print the sizes of the training and testing sets\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Testing set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with missing data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature: Filling missing values with the mean temperature value for the same time of day from nearby days (e.g., the same hour on different days).\n",
    "# dew_point: Filling missing values with the mean dew point value for the same time of day from nearby days (e.g., the same hour on different days).\n",
    "# visibility: Filling missing values with the mean visibility value for the same time of day from nearby days (e.g., the same hour on different days).\n",
    "\n",
    "def fill_missing_with_mean_same_time_neaby_days(df, time_column, column, window_size=7):\n",
    "    \"\"\"\n",
    "    Fill missing values with the mean  for the same time of day from nearby days.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing time series data with columns 'time' and 'temperature'.\n",
    "    - time_column: Name of the column containing timestamps.\n",
    "    - temperature_column: Name of the column containing temperature values.\n",
    "    - window_size: Number of days to consider for calculating the mean temperature. Default is 7 days (1 week).\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with missing temperature values filled with the mean temperature.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by the 'time' column if not already sorted\n",
    "    df.sort_values(by=time_column, inplace=True)\n",
    "\n",
    "    # Create a new DataFrame to store the filled values\n",
    "    filled_df = df.copy()\n",
    "\n",
    "    # Iterate through rows with missing temperature values\n",
    "    for index, row in filled_df.iterrows():\n",
    "        if pd.isna(row[column]):\n",
    "            # Get the timestamp and hour of the missing value\n",
    "            timestamp = row[time_column]\n",
    "            hour = timestamp.hour\n",
    "\n",
    "            # Calculate the time window for mean calculation\n",
    "            start_time = timestamp - pd.DateOffset(days=window_size)\n",
    "            end_time = timestamp + pd.DateOffset(days=window_size)\n",
    "\n",
    "            # Filter the DataFrame to select data within the time window\n",
    "            selected_data = df[(df[time_column] >= start_time) & (df[time_column] <= end_time)]\n",
    "\n",
    "            # Calculate the mean temperature for the same hour of the day\n",
    "            mean_temperature = selected_data[selected_data[time_column].dt.hour == hour][column].mean()\n",
    "\n",
    "            # Fill the missing temperature value with the mean temperature\n",
    "            filled_df.at[index, column] = mean_temperature\n",
    "\n",
    "    return filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind speed: since wind speed contains only 2 missing values, we will fill them with the mean wind speed\n",
    "\n",
    "def fill_missing_wind_speed_values(df):\n",
    "    \"\"\"\n",
    "    Fill missing wind speed values with the mean wind speed.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with missing wind speed values filled with the mean wind speed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fill missing wind speed values with the mean wind speed\n",
    "    df['wind_speed'].fillna(df['wind_speed'].mean(), inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind direction: wind direction have significant number of missing values, so we will fill them with the mode \n",
    "\n",
    "def fill_missing_wind_direction_values(df):\n",
    "    \"\"\"\n",
    "    Fill missing wind direction values with the mode wind direction.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with missing wind direction values filled with the mode wind direction.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fill missing wind direction values with the mode wind direction\n",
    "    df['wind_direction'].fillna(df['wind_direction'].mode()[0], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the training data and testing data\n",
    "train_data = fill_missing_with_mean_same_time_neaby_days(train_data, 'time', 'temperature')\n",
    "train_data = fill_missing_with_mean_same_time_neaby_days(train_data, 'time', 'dew_point')\n",
    "train_data = fill_missing_with_mean_same_time_neaby_days(train_data, 'time', 'visibility')\n",
    "train_data = fill_missing_wind_speed_values(train_data)\n",
    "train_data = fill_missing_wind_direction_values(train_data)\n",
    "\n",
    "test_data = fill_missing_with_mean_same_time_neaby_days(test_data, 'time', 'temperature')\n",
    "test_data = fill_missing_with_mean_same_time_neaby_days(test_data, 'time', 'dew_point')\n",
    "test_data = fill_missing_with_mean_same_time_neaby_days(test_data, 'time', 'visibility')\n",
    "test_data = fill_missing_wind_speed_values(test_data)\n",
    "test_data = fill_missing_wind_direction_values(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate humidity\n",
    "train_data['relative_humidity'] = 100 * (np.exp((17.625 * train_data['dew_point']) / (243.04 + train_data['dew_point'])) / np.exp((17.625 * train_data['temperature']) / (243.04 + train_data['temperature'])))\n",
    "test_data['relative_humidity'] = 100 * (np.exp((17.625 * test_data['dew_point']) / (243.04 + test_data['dew_point'])) / np.exp((17.625 * test_data['temperature']) / (243.04 + test_data['temperature'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_data.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values,\n",
    "            cmap='Blues')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the highest correlation\n",
    "corr.abs().unstack().sort_values(ascending=False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_feature(df, lag_intervals, column):\n",
    "    \"\"\"\n",
    "    Create lagged features.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing time series data with a 'time' column.\n",
    "    - lag_intervals: List of lag intervals to use for creating lagged features.\n",
    "    - column: Name of the column to use for creating lagged features.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with lagged features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create lagged features\n",
    "    for lag in lag_intervals:\n",
    "        df[f'{column}_lag_{lag}'] = df[column].shift(lag)\n",
    "\n",
    "    return df\n",
    "lag_intervals = [1, 3]\n",
    "\n",
    "train_data = lag_feature(train_data, lag_intervals, 'temperature')\n",
    "train_data = lag_feature(train_data, lag_intervals, 'relative_humidity')\n",
    "\n",
    "test_data = lag_feature(test_data, lag_intervals, 'temperature')\n",
    "test_data = lag_feature(test_data, lag_intervals, 'relative_humidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['day_of_week'] = train_data['time'].dt.dayofweek\n",
    "train_data['hour_of_day'] = train_data['time'].dt.hour\n",
    "\n",
    "test_data['day_of_week'] = test_data['time'].dt.dayofweek\n",
    "test_data['hour_of_day'] = test_data['time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Nan values with 0 for the lagged features since they are the first values in the time series\n",
    "train_data['temperature_lag_1'].fillna(0, inplace=True)\n",
    "train_data['temperature_lag_3'].fillna(0, inplace=True)\n",
    "train_data['relative_humidity_lag_1'].fillna(0, inplace=True)\n",
    "train_data['relative_humidity_lag_3'].fillna(0, inplace=True)\n",
    "\n",
    "test_data['temperature_lag_1'].fillna(0, inplace=True)\n",
    "test_data['temperature_lag_3'].fillna(0, inplace=True)\n",
    "test_data['relative_humidity_lag_1'].fillna(0, inplace=True)\n",
    "test_data['relative_humidity_lag_3'].fillna(0, inplace=True)\n",
    "\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_numeric_columns(df):\n",
    "    \"\"\"\n",
    "    Standardize all numeric columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing time series data.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with numeric columns (except 'time') standardized.\n",
    "    \"\"\"\n",
    "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "    for column in numeric_columns:\n",
    "        if column != 'time':\n",
    "            mean = df[column].mean()\n",
    "            std = df[column].std()\n",
    "            df[column] = (df[column] - mean) / std\n",
    "    return df\n",
    "\n",
    "train_data = standardize_numeric_columns(train_data)\n",
    "test_data = standardize_numeric_columns(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'temperature', 'dew_point', 'wind_speed', 'wind_direction', 'visibility', 'clouds.total_cover',\n",
    "    'relative_humidity', 'temperature_lag_1', 'temperature_lag_3',\n",
    "    'relative_humidity_lag_1', 'relative_humidity_lag_3',\n",
    "    'day_of_week', 'hour_of_day'\n",
    "]\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['temperature']  \n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data['temperature']  \n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R2) Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "\n",
    "num_round = 100  # Number of boosting rounds (iterations)\n",
    "model = lgb.train(params, train_data, num_round)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R2) Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.values, dtype=torch.float32).to(DEVICE)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).to(DEVICE)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32).to(DEVICE)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesChunkDataset(Dataset):\n",
    "    def __init__(self, data, targets, sequence_length):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.data[idx:idx+self.sequence_length],\n",
    "            self.targets[idx+self.sequence_length-1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 1  # Adjust this based on your needs\n",
    "batch_size = 32\n",
    "\n",
    "# Create instances of your custom dataset for training and testing\n",
    "train_dataset = TimeSeriesChunkDataset(X_train, y_train, sequence_length)\n",
    "test_dataset = TimeSeriesChunkDataset(X_test, y_test, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True  # Optional: Drop the last batch if it's smaller than batch_size\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_size, 128)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(DEVICE)\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(DEVICE)\n",
    "\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 13\n",
    "hidden_size = 64\n",
    "num_layers = 32\n",
    "num_classes = 1\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers, sequence_length).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
